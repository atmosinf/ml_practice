{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fd90e7c",
   "metadata": {},
   "source": [
    "### in this notebook we'll play with RNNs to get an understanding of how they work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ecc9e6",
   "metadata": {},
   "source": [
    "note: at the point of creating this notebook, my experience with RNN is close to none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47f15a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eefbf69",
   "metadata": {},
   "source": [
    "Disregarding overfitting, etc., we'll create a model that tries to predict the next letter/sequence of letters in the alphabet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab6db55",
   "metadata": {},
   "source": [
    "### prepare the dataset for testing tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6377ab4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96002b6",
   "metadata": {},
   "source": [
    "tokenize the dataset. (change the letters to numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "318ef657",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_tokenized = [i for i in np.arange(len(dataset))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "603d9a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d13ca76",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_tokenized = torch.FloatTensor(dataset_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47ad2b61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
       "        14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d92d270d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_tokenized.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa0bcf4",
   "metadata": {},
   "source": [
    "now one hot the tokenized tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e8ed846",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "one_hot is only applicable to index tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3323/1527405303.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_tokenized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: one_hot is only applicable to index tensor."
     ]
    }
   ],
   "source": [
    "F.one_hot(dataset_tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29501d71",
   "metadata": {},
   "source": [
    "hmm.. i think the tokenized tensor should be of datatype integer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "992d8245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23, 24, 25], dtype=torch.int32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_tokenized = [i for i in np.arange(len(dataset))]\n",
    "dataset_tokenized = torch.IntTensor(dataset_tokenized)\n",
    "dataset_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "399ea825",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "one_hot is only applicable to index tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3777/1527405303.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_tokenized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: one_hot is only applicable to index tensor."
     ]
    }
   ],
   "source": [
    "F.one_hot(dataset_tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41218c8a",
   "metadata": {},
   "source": [
    "huh. that didnt work either"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1863fa6f",
   "metadata": {},
   "source": [
    "further research showed that the tokenized input tensor for .one_hot should be an int64 tensor: https://github.com/ray-project/ray/issues/11401#issuecomment-721700627"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3b51ff44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         1, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 1]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_onehot = F.one_hot(dataset_tokenized.long())\n",
    "dataset_onehot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9caebe31",
   "metadata": {},
   "source": [
    "okay. that worked. .long() converts the tensor to int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "994eaf6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_onehot.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf9b67b",
   "metadata": {},
   "source": [
    "#### we'll create a vocab dict which we will use later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3838f07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_dict = {dataset[i]:i for i in np.arange(len(dataset))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1467d3de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0,\n",
       " 'b': 1,\n",
       " 'c': 2,\n",
       " 'd': 3,\n",
       " 'e': 4,\n",
       " 'f': 5,\n",
       " 'g': 6,\n",
       " 'h': 7,\n",
       " 'i': 8,\n",
       " 'j': 9,\n",
       " 'k': 10,\n",
       " 'l': 11,\n",
       " 'm': 12,\n",
       " 'n': 13,\n",
       " 'o': 14,\n",
       " 'p': 15,\n",
       " 'q': 16,\n",
       " 'r': 17,\n",
       " 's': 18,\n",
       " 't': 19,\n",
       " 'u': 20,\n",
       " 'v': 21,\n",
       " 'w': 22,\n",
       " 'x': 23,\n",
       " 'y': 24,\n",
       " 'z': 25}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c439454",
   "metadata": {},
   "source": [
    "### test an rnn cell "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fce6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnntest = nn.RNN(input_size=4, hidden_size=12, num_layers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8f1007e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(4, 12, num_layers=3)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnntest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81898860",
   "metadata": {},
   "source": [
    "create a sample input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d9568e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4.])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampleinp = torch.FloatTensor((1,2,3,4))\n",
    "sampleinp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b9039e2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampleinp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "de88e364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 2., 3., 4.]]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampleinp.unsqueeze_(0).unsqueeze_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d0877d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 4])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampleinp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0599ee5",
   "metadata": {},
   "source": [
    "read about input shape: https://pytorch.org/docs/stable/generated/torch.nn.RNN.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f0f5002b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleout = rnntest(sampleinp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "816620ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.8106, -0.1224, -0.0200, -0.2534, -0.5853,  0.6180, -0.1380,\n",
       "           -0.1661, -0.1332, -0.3216,  0.5315,  0.1052]]],\n",
       "        grad_fn=<StackBackward0>),\n",
       " tensor([[[-0.9076,  0.3143,  0.3579,  0.8390,  0.9330,  0.9481,  0.4786,\n",
       "            0.0115, -0.7938, -0.8034, -0.1920, -0.2838]],\n",
       " \n",
       "         [[-0.3131,  0.4416, -0.6035, -0.2584, -0.5068, -0.4455, -0.0284,\n",
       "           -0.3195, -0.6628,  0.6726, -0.0493,  0.8301]],\n",
       " \n",
       "         [[ 0.8106, -0.1224, -0.0200, -0.2534, -0.5853,  0.6180, -0.1380,\n",
       "           -0.1661, -0.1332, -0.3216,  0.5315,  0.1052]]],\n",
       "        grad_fn=<StackBackward0>))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampleout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17a38d3",
   "metadata": {},
   "source": [
    "you can see above that sampleout[0] has the output of the final layer, and sampleoutput[1] stores the outputs of all the layers in the stacked recurrent network. sampleout[0] and the last row of sampleout[1] are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6cf4fe14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sampleout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d5073208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 12])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampleout[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "24fb4218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 12])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampleout[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cad864b",
   "metadata": {},
   "source": [
    "### run a few random tests "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60dae256",
   "metadata": {},
   "source": [
    "#### what if the input shape does not match "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "00037fcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 2., 3., 4.]]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampleinp1 = torch.FloatTensor((1,2,3,4)).unsqueeze_(0).unsqueeze_(0)\n",
    "sampleinp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "566b9306",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnntest1 = nn.RNN(input_size=3, hidden_size=12, num_layers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0fd73b71",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "input.size(-1) must be equal to input_size. Expected 3, got 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3777/4031018415.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrnntest1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampleinp1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/udacitycvenv/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/udacitycvenv/lib/python3.9/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mhx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m         \u001b[0m_impl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_rnn_impls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/udacitycvenv/lib/python3.9/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         \u001b[0mexpected_hidden_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_expected_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/udacitycvenv/lib/python3.9/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_input\u001b[0;34m(self, input, batch_sizes)\u001b[0m\n\u001b[1;32m    203\u001b[0m                     expected_input_dim, input.dim()))\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m    206\u001b[0m                 'input.size(-1) must be equal to input_size. Expected {}, got {}'.format(\n\u001b[1;32m    207\u001b[0m                     self.input_size, input.size(-1)))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 3, got 4"
     ]
    }
   ],
   "source": [
    "rnntest1(sampleinp1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cee0ae8",
   "metadata": {},
   "source": [
    "### Understand the output of the RNN, and how the weights are multiplied with the inputs and hidden states"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2da9b77",
   "metadata": {},
   "source": [
    "look at the equation here: https://pytorch.org/docs/stable/generated/torch.nn.RNN.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3f19a804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.1575, 0.8601, 0.1959]]], grad_fn=<TransposeBackward1>),\n",
       " tensor([[[ 0.7231, -0.7849,  0.3994]],\n",
       " \n",
       "         [[ 0.1575,  0.8601,  0.1959]]], grad_fn=<StackBackward0>))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampleinp2 = torch.FloatTensor((1,0,0,0)).unsqueeze_(0).unsqueeze_(0)\n",
    "rnntest2 = nn.RNN(input_size=4, hidden_size=3, num_layers=2, batch_first=True)\n",
    "h0 = torch.zeros(2, 1, 3)\n",
    "sampleout2 = rnntest2(sampleinp2, h0)\n",
    "sampleout2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "54de847f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.]]])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb72469",
   "metadata": {},
   "source": [
    "below cell shows all the weights and biases in both the layers. the first 4 tensors belong to the first layer in the stacked rnn, and the last 4 tensors belong to the top layer in the stacked rnn.\n",
    "\n",
    "lets look at the first four tensors, ie, the first layer in the stacked rnn. cross check with the equation provided in the pytorch rnn documentation - https://pytorch.org/docs/stable/generated/torch.nn.RNN.html\n",
    "\n",
    "the 1st tensor has the weights for the 4 inputs over 3 time steps (hidden size = time step) - Wih <br>\n",
    "the 3rd tensor has the biases for the inputs for 3 time steps - bih\n",
    "\n",
    "the 2st tensor has the weights for the 3 hidden states. on testing i see that this is always a square matrix. - Whh<br>\n",
    "the 4th tensor has the biases for the hidden states for 3 time steps - bhh\n",
    "\n",
    "xt is the input for that time step <br>\n",
    "h(t-1) is the output of the previous time step without activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "cfc3ce02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Parameter containing:\n",
       "  tensor([[-0.4173,  0.4174,  0.2059, -0.4597],\n",
       "          [-0.0723, -0.5551,  0.4747, -0.4508],\n",
       "          [-0.1360,  0.3744,  0.3179,  0.1486]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.2320, -0.0877, -0.5017],\n",
       "          [-0.3981, -0.3421, -0.0617],\n",
       "          [-0.0402,  0.1713,  0.5218]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.1127,  0.2711, -0.1279], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.2040, -0.0273, -0.0363], requires_grad=True)],\n",
       " [Parameter containing:\n",
       "  tensor([[ 0.4758,  0.1579, -0.4541],\n",
       "          [-0.1924, -0.3847, -0.1160],\n",
       "          [-0.1088, -0.2506, -0.5486]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0106,  0.2868,  0.2903],\n",
       "          [-0.1309, -0.0867, -0.0035],\n",
       "          [ 0.0546,  0.0871, -0.2004]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([-0.1665,  0.5583, -0.1764], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([ 0.1633, -0.1199, -0.2487], requires_grad=True)]]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnntest2.all_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8406be",
   "metadata": {},
   "source": [
    "let's look at the first layer outputs separately"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800b58a8",
   "metadata": {},
   "source": [
    "the weights for the 4 inputs over 3 time steps (hidden size = time step) - Wih:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "85040c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.4173,  0.4174,  0.2059, -0.4597],\n",
       "        [-0.0723, -0.5551,  0.4747, -0.4508],\n",
       "        [-0.1360,  0.3744,  0.3179,  0.1486]], requires_grad=True)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnntest2.weight_ih_l0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7959f7",
   "metadata": {},
   "source": [
    "the biases for the inputs for 3 time steps - bih:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "803f3e3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 0.1127,  0.2711, -0.1279], requires_grad=True)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnntest2.bias_ih_l0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badfd736",
   "metadata": {},
   "source": [
    "the weights for the 3 hidden states. on testing i see that this is always a square matrix. - Whh:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "a693af0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.2320, -0.0877, -0.5017],\n",
       "        [-0.3981, -0.3421, -0.0617],\n",
       "        [-0.0402,  0.1713,  0.5218]], requires_grad=True)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnntest2.weight_hh_l0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b046cb",
   "metadata": {},
   "source": [
    "the biases for the hidden states for 3 time steps - bhh:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "5454cf89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 0.2040, -0.0273, -0.0363], requires_grad=True)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnntest2.bias_hh_l0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ffc052",
   "metadata": {},
   "source": [
    "output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "6910c07b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.1078,  0.4022, -0.2884]]], grad_fn=<TransposeBackward1>),\n",
       " tensor([[[-0.1002,  0.1698, -0.2915]],\n",
       " \n",
       "         [[ 0.1078,  0.4022, -0.2884]]], grad_fn=<StackBackward0>))"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampleout2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98813761",
   "metadata": {},
   "source": [
    "analyse the weights for the **first time step in the first layer**<br>\n",
    "using the equation tanh(Wihxt + bih + Whhh(t-1) + bhh), <br>\n",
    "Wih = [-0.4173,  0.4174,  0.2059, -0.4597] <br>\n",
    "xt = [1,0,0,0] <br>\n",
    "bih = [0.1127] <br>\n",
    "Whh = [ 0.2320, -0.0877, -0.5017] <br>\n",
    "h(t-1) = [0, 0, 0] <br>\n",
    "bhh = [0.2040]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ae9401",
   "metadata": {},
   "source": [
    "manually test the formula:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "0d2ec82e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.10026199880626045"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.tanh(np.matmul([-0.4173,  0.4174,  0.2059, -0.4597], [1,0,0,0]) + 0.1127 \\\n",
    "        + np.matmul([ 0.2320, -0.0877, -0.5017],[0, 0, 0]) + 0.2040)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9a2ecc",
   "metadata": {},
   "source": [
    "check the output of the first time step in the first layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "5c31012f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1002,  0.1698, -0.2915]],\n",
       "\n",
       "        [[ 0.1078,  0.4022, -0.2884]]], grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampleout2[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa08f295",
   "metadata": {},
   "source": [
    "**They match! So we can confirm that our understanding of the weights and biases tensors is correct**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb882fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "udacitycvenv",
   "language": "python",
   "name": "udacitycvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
